{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 02- Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('../data/cleaned_tweets_test.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_true = []\n",
    "for word in df[df.category == 'true'].cleaned.str.split().to_list():\n",
    "    bow_true += word\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_unreliable = []\n",
    "for word in df[df.category == 'unreliable'].cleaned.str.split().to_list():\n",
    "    bow_unreliable += word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2829"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bow_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3294"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bow_unreliable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1089"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(bow_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1583"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(set(bow_unreliable))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = bow_true + bow_unreliable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts =  [(tweet, cat) for tweet, cat in zip(df.cleaned.to_list(), df.category.to_list())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets, cats = (zip(*texts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "testing_words = set(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_training_cbow = pickle.load(open('../data/we_cbow_training.pickle', 'rb'))\n",
    "we_training_sg = pickle.load(open('../data/we_sg_training.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_words = pickle.load(open('../data/training_words_set.pickle', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "596"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len([word for word in testing_words if word not in training_words])\n",
    "\n",
    "# this might create a significant issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [tweet.split() for tweet in tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train word embeddings on test dataset and only extract embeddings that are not in training\n",
    "\n",
    "test_cbow = Word2Vec(corpus, vector_size=300, min_count=1, epochs=10, seed=42)\n",
    "test_sg = Word2Vec(corpus, sg=1, vector_size=300, min_count=1, epochs=10, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_test_cbow = {word: test_cbow.wv[word] for word in testing_words if word not in training_words}\n",
    "we_test_sg = {word: test_sg.wv[word] for word in testing_words if word not in training_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "we_cbow = we_training_cbow | we_test_cbow\n",
    "we_sg = we_training_sg | we_test_sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def meaner(word_embedding, tweets):\n",
    "    tweet_embedding = {}\n",
    "    for i, tweet in enumerate(tweets):\n",
    "        tweet_embedding[tweet] = np.mean(np.array([word_embedding[word] for word in tweets[i].split()]), axis=0)\n",
    "    return tweet_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_cbow = meaner(we_cbow, tweets)\n",
    "te_sg = meaner(we_sg, tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(557, 557)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(te_cbow), len(te_sg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "te_cbow_df = pd.DataFrame(te_cbow).T.reset_index().rename(columns={'index':'tweet'})\n",
    "te_cbow_df['category'] = cats\n",
    "te_cbow_df['label'] = te_cbow_df.category.map({'unreliable':0, 'true':1})\n",
    "te_cbow_df = te_cbow_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "te_sg_df = pd.DataFrame(te_sg).T.reset_index().rename(columns={'index':'tweet'})\n",
    "te_sg_df['category'] = cats\n",
    "te_sg_df['label'] = te_sg_df.category.map({'unreliable':0, 'true':1})\n",
    "te_sg_df = te_sg_df.sample(frac=1, random_state=42).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>...</th>\n",
       "      <th>292</th>\n",
       "      <th>293</th>\n",
       "      <th>294</th>\n",
       "      <th>295</th>\n",
       "      <th>296</th>\n",
       "      <th>297</th>\n",
       "      <th>298</th>\n",
       "      <th>299</th>\n",
       "      <th>category</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>nation health professional continue manage cor...</td>\n",
       "      <td>-0.000578</td>\n",
       "      <td>-0.037394</td>\n",
       "      <td>0.004011</td>\n",
       "      <td>-0.067333</td>\n",
       "      <td>0.074218</td>\n",
       "      <td>-0.015869</td>\n",
       "      <td>0.181918</td>\n",
       "      <td>0.168126</td>\n",
       "      <td>-0.073878</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016714</td>\n",
       "      <td>0.090119</td>\n",
       "      <td>0.063498</td>\n",
       "      <td>0.176591</td>\n",
       "      <td>0.260096</td>\n",
       "      <td>0.038692</td>\n",
       "      <td>-0.030767</td>\n",
       "      <td>0.040254</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>toronto public health set coronavirus hotline ...</td>\n",
       "      <td>-0.002870</td>\n",
       "      <td>-0.045381</td>\n",
       "      <td>0.022516</td>\n",
       "      <td>-0.095714</td>\n",
       "      <td>0.118483</td>\n",
       "      <td>-0.024555</td>\n",
       "      <td>0.288207</td>\n",
       "      <td>0.276162</td>\n",
       "      <td>-0.104954</td>\n",
       "      <td>...</td>\n",
       "      <td>0.025484</td>\n",
       "      <td>0.145816</td>\n",
       "      <td>0.100598</td>\n",
       "      <td>0.281570</td>\n",
       "      <td>0.413442</td>\n",
       "      <td>0.074131</td>\n",
       "      <td>-0.048276</td>\n",
       "      <td>0.067406</td>\n",
       "      <td>true</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hey trumptrain official warns trump ignorant c...</td>\n",
       "      <td>0.000579</td>\n",
       "      <td>-0.038867</td>\n",
       "      <td>0.018511</td>\n",
       "      <td>-0.079097</td>\n",
       "      <td>0.090032</td>\n",
       "      <td>-0.019367</td>\n",
       "      <td>0.219561</td>\n",
       "      <td>0.199829</td>\n",
       "      <td>-0.086984</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023660</td>\n",
       "      <td>0.109519</td>\n",
       "      <td>0.072719</td>\n",
       "      <td>0.218561</td>\n",
       "      <td>0.321472</td>\n",
       "      <td>0.058530</td>\n",
       "      <td>-0.037280</td>\n",
       "      <td>0.053943</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lie us coronaviruse</td>\n",
       "      <td>-0.004057</td>\n",
       "      <td>-0.025749</td>\n",
       "      <td>0.011759</td>\n",
       "      <td>-0.054163</td>\n",
       "      <td>0.067528</td>\n",
       "      <td>-0.011438</td>\n",
       "      <td>0.159022</td>\n",
       "      <td>0.160850</td>\n",
       "      <td>-0.060790</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014135</td>\n",
       "      <td>0.083286</td>\n",
       "      <td>0.062069</td>\n",
       "      <td>0.143551</td>\n",
       "      <td>0.212194</td>\n",
       "      <td>0.041828</td>\n",
       "      <td>-0.028897</td>\n",
       "      <td>0.037737</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>maga hat made china may infected coronavirus s...</td>\n",
       "      <td>-0.005614</td>\n",
       "      <td>-0.033827</td>\n",
       "      <td>0.017325</td>\n",
       "      <td>-0.067794</td>\n",
       "      <td>0.076886</td>\n",
       "      <td>-0.017765</td>\n",
       "      <td>0.195124</td>\n",
       "      <td>0.180815</td>\n",
       "      <td>-0.074958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017363</td>\n",
       "      <td>0.097263</td>\n",
       "      <td>0.069475</td>\n",
       "      <td>0.198881</td>\n",
       "      <td>0.293775</td>\n",
       "      <td>0.051552</td>\n",
       "      <td>-0.034167</td>\n",
       "      <td>0.047908</td>\n",
       "      <td>unreliable</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               tweet         0         1  \\\n",
       "0  nation health professional continue manage cor... -0.000578 -0.037394   \n",
       "1  toronto public health set coronavirus hotline ... -0.002870 -0.045381   \n",
       "2  hey trumptrain official warns trump ignorant c...  0.000579 -0.038867   \n",
       "3                                lie us coronaviruse -0.004057 -0.025749   \n",
       "4  maga hat made china may infected coronavirus s... -0.005614 -0.033827   \n",
       "\n",
       "          2         3         4         5         6         7         8  ...  \\\n",
       "0  0.004011 -0.067333  0.074218 -0.015869  0.181918  0.168126 -0.073878  ...   \n",
       "1  0.022516 -0.095714  0.118483 -0.024555  0.288207  0.276162 -0.104954  ...   \n",
       "2  0.018511 -0.079097  0.090032 -0.019367  0.219561  0.199829 -0.086984  ...   \n",
       "3  0.011759 -0.054163  0.067528 -0.011438  0.159022  0.160850 -0.060790  ...   \n",
       "4  0.017325 -0.067794  0.076886 -0.017765  0.195124  0.180815 -0.074958  ...   \n",
       "\n",
       "        292       293       294       295       296       297       298  \\\n",
       "0  0.016714  0.090119  0.063498  0.176591  0.260096  0.038692 -0.030767   \n",
       "1  0.025484  0.145816  0.100598  0.281570  0.413442  0.074131 -0.048276   \n",
       "2  0.023660  0.109519  0.072719  0.218561  0.321472  0.058530 -0.037280   \n",
       "3  0.014135  0.083286  0.062069  0.143551  0.212194  0.041828 -0.028897   \n",
       "4  0.017363  0.097263  0.069475  0.198881  0.293775  0.051552 -0.034167   \n",
       "\n",
       "        299    category  label  \n",
       "0  0.040254  unreliable      0  \n",
       "1  0.067406        true      1  \n",
       "2  0.053943  unreliable      0  \n",
       "3  0.037737  unreliable      0  \n",
       "4  0.047908  unreliable      0  \n",
       "\n",
       "[5 rows x 303 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "te_cbow_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(te_cbow_df, open(\"../data/te_cbow_df_testing_extra.pickle\", \"wb\"))\n",
    "pickle.dump(te_sg_df, open(\"../data/te_sg_df_testing_extra.pickle\", \"wb\"))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "033bd3c1329338defdc4c98345d63580936211b5a58345c09a4ef95f2034f40b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('venv': venv)",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
